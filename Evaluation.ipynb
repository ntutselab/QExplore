{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "source": [
    "from apted import APTED\n",
    "from apted.helpers import Tree\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob, os\n",
    "from tqdm import tqdm\n",
    "import itertools\n",
    "from bs4 import BeautifulSoup\n",
    "import bs4\n",
    "#from collections import defaultdict\n",
    "\n",
    "from collections import OrderedDict, Callable\n",
    "\n",
    "class DefaultOrderedDict(OrderedDict):\n",
    "    # Source: http://stackoverflow.com/a/6190500/562769\n",
    "    def __init__(self, default_factory=None, *a, **kw):\n",
    "        if (default_factory is not None and\n",
    "           not isinstance(default_factory, Callable)):\n",
    "            raise TypeError('first argument must be callable')\n",
    "        OrderedDict.__init__(self, *a, **kw)\n",
    "        self.default_factory = default_factory\n",
    "\n",
    "    def __getitem__(self, key):\n",
    "        try:\n",
    "            return OrderedDict.__getitem__(self, key)\n",
    "        except KeyError:\n",
    "            return self.__missing__(key)\n",
    "\n",
    "    def __missing__(self, key):\n",
    "        if self.default_factory is None:\n",
    "            raise KeyError(key)\n",
    "        self[key] = value = self.default_factory()\n",
    "        return value\n",
    "\n",
    "    def __reduce__(self):\n",
    "        if self.default_factory is None:\n",
    "            args = tuple()\n",
    "        else:\n",
    "            args = self.default_factory,\n",
    "        return type(self), args, None, None, self.items()\n",
    "\n",
    "    def copy(self):\n",
    "        return self.__copy__()\n",
    "\n",
    "    def __copy__(self):\n",
    "        return type(self)(self.default_factory, self)\n",
    "\n",
    "    def __deepcopy__(self, memo):\n",
    "        import copy\n",
    "        return type(self)(self.default_factory,\n",
    "                          copy.deepcopy(self.items()))\n",
    "\n",
    "    def __repr__(self):\n",
    "        return 'OrderedDefaultDict(%s, %s)' % (self.default_factory,\n",
    "                                               OrderedDict.__repr__(self))\n",
    "\n",
    "\n",
    "\n",
    "def defaultVal():\n",
    "    return [[],0]\n",
    "\n",
    "def makeTree(file):\n",
    "    with open(file,\"r\") as f:\n",
    "        S = f.read()\n",
    "    S = S.strip()\n",
    "    S = S.replace(\"\\n\",\"\")\n",
    "    #S = S.replace(\" \",\"\")\n",
    "    S = S.replace(\"\\t\",\"\")\n",
    "    S = S.replace(\"\\r\",\"\")\n",
    "    soup = BeautifulSoup(S, \"html.parser\")\n",
    "    return soup\n",
    "\n",
    "def recursiveChildBfs(bs):\n",
    "    root = bs\n",
    "    stack = [root]\n",
    "    count=0\n",
    "    parrent = [None]\n",
    "    while len(stack) != 0:\n",
    "        node = stack.pop(0)\n",
    "        pnode = parrent.pop(0)\n",
    "        if node is not bs:\n",
    "            if node.name!=None:\n",
    "                yield node.name+\"~\"+str(count),pnode\n",
    "            else:\n",
    "                yield node.name,pnode\n",
    "        if hasattr(node, 'children'):\n",
    "            for child in node.children:\n",
    "                stack.append(child)\n",
    "                parrent.append(node.name+\"~\"+str(count))\n",
    "        count+=1\n",
    "\n",
    "def visit(tagdict,c,tree):\n",
    "    tree+=\"{\"\n",
    "    tree+=c.split(\"~\")[0]\n",
    "    for i in tagdict[c][0]:\n",
    "        tree = visit(tagdict,i,tree)\n",
    "        tree+=\"}\"\n",
    "    return tree        \n",
    "\n",
    "def generateTree(file):\n",
    "    html = makeTree(file)\n",
    "    tagdict = DefaultOrderedDict(defaultVal)\n",
    "    for c,p in recursiveChildBfs(html):\n",
    "        if c!=None:\n",
    "            tagdict[p][0].append(c)\n",
    "            tagdict[p][1]+=1\n",
    "\n",
    "\n",
    "    tree = \"{\"\n",
    "    for x,y in zip(list(tagdict.keys())[1::],list(tagdict.values())[1::]):\n",
    "        tree+=x.split(\"~\")[0]\n",
    "        for c in y[0]:\n",
    "            #tree+=\"{\"\n",
    "            #tree+=c\n",
    "            tree = visit(tagdict,c,tree)\n",
    "            tree+=\"}\"\n",
    "        tree+=\"}\"\n",
    "        break\n",
    "    nNodes = 0\n",
    "    for x in tagdict.keys():\n",
    "        nNodes+=tagdict[x][1]\n",
    "    return tree,nNodes\n",
    "\n",
    "\n",
    "    \n",
    "from collections import defaultdict\n",
    "import pickle\n",
    "import json\n",
    "\n",
    "def load_stateMap(name):\n",
    "    with open(name) as json_file:\n",
    "        data = defaultdict(factory)\n",
    "        data2 = json.load(json_file)\n",
    "        data.update(data2)\n",
    "    return data\n",
    "\n",
    "def factory():\n",
    "    return {\"src\":\"\",\"edges\":[],\"url\":\"\",\"start\":0}\n",
    "\n",
    "\n",
    "import networkx as nx\n",
    "\n",
    "def makeGraph_Qexplore(statedict):\n",
    "    DG = nx.DiGraph()\n",
    "    SFG = load_stateMap(statedict)\n",
    "    count=1\n",
    "    stateNamesBig = {}\n",
    "    stateNamesSmall = {}\n",
    "    edgemap = {}\n",
    "    indexstate = \"\"\n",
    "    indexlist = [x for x in SFG.keys() if SFG[x][\"start\"]==1]\n",
    "    statesfile = [file.split(\"/\")[-1].split(\".html\")[0] for file in glob.glob(\"./Q_Result/*.html\")]\n",
    "    for x in SFG.keys():\n",
    "        if x in indexlist:\n",
    "            stateNamesSmall[\"index\"+str(count)] = x\n",
    "            stateNamesBig[x] = \"index\"+str(count)\n",
    "        else:\n",
    "            stateNamesSmall[\"S\"+str(count)] = x\n",
    "            stateNamesBig[x] = \"S\"+str(count)\n",
    "        count+=1\n",
    "    sss = [x for x in set(statesfile).difference(set(SFG.keys())) if x not in [\"index\",\"temp\"]]\n",
    "    for x in sss:\n",
    "        stateNamesSmall[\"S\"+str(count)] = x\n",
    "        stateNamesBig[x] = \"S\"+str(count)\n",
    "        count+=1\n",
    "\n",
    "    DG.add_nodes_from(stateNamesSmall.keys())\n",
    "    count = 0\n",
    "    for state in stateNamesSmall.keys():\n",
    "        for edge in SFG[stateNamesSmall[state]]['edges']:\n",
    "            if edge[\"state\"] in statesfile:\n",
    "                edgemap[edge[\"action\"]] = count\n",
    "                count+=1\n",
    "        \n",
    "    for state in stateNamesSmall.keys():\n",
    "        edges = [(state,stateNamesBig[edge[\"state\"]]) for edge in SFG[stateNamesSmall[state]]['edges'] if edge[\"state\"] in statesfile]\n",
    "        #DG.add_edges_from()\n",
    "        #print(edges)\n",
    "        DG.add_edges_from(edges)\n",
    "    return DG,stateNamesBig,stateNamesSmall,indexlist,SFG,edgemap\n",
    "\n",
    "def makeGraph_crawljax(resultfile,baseurl):\n",
    "    with open(resultfile) as json_file: \n",
    "        data = json.load(json_file)\n",
    "    DG = nx.DiGraph()\n",
    "    keys = [k for k in data[\"states\"].keys() if baseurl in data[\"states\"][k][\"url\"]]\n",
    "    \n",
    "    aa = os.listdir(\"./doms/\")\n",
    "    keys = [k for k in keys if k+\".html\" in aa]\n",
    "    DG.add_nodes_from(keys)\n",
    "    edges = [(edge[\"from\"],edge[\"to\"]) for edge in data[\"edges\"] if edge[\"from\"] in keys and edge[\"to\"] in keys]\n",
    "    DG.add_edges_from(edges)\n",
    "    return DG,data\n",
    "\n",
    "def generateSimplePaths_QExplore(statedict):\n",
    "    DG,stateNamesBig,stateNamesSmall,indexlist,SFG,edgemap = makeGraph_Qexplore(statedict)\n",
    "    pathdict = {}\n",
    "    for node in tqdm(DG.nodes):\n",
    "        for index in indexlist:\n",
    "            paths = nx.all_simple_paths(DG, source=stateNamesBig[index], target=node)\n",
    "            pathlist = []\n",
    "            for path in paths:\n",
    "                i=0\n",
    "                #temp = []\n",
    "                s = \"\"\n",
    "                while(i<len(path)-1):\n",
    "                    edar = []\n",
    "                    for edge in SFG[stateNamesSmall[path[i]]][\"edges\"]:\n",
    "                        if edge[\"state\"]==stateNamesSmall[path[i+1]]:\n",
    "                            #temp.append(path[i]+edge[\"action\"])\n",
    "                            #print(\"hello\")\n",
    "                            edar.append(path[i])\n",
    "                    s+=\"|\".join(set(edar))\n",
    "                    s+=\"->\"\n",
    "                    i+=1\n",
    "                temp = splitstring(s)\n",
    "                pathlist.extend(temp)\n",
    "        pathdict[node] = pathlist\n",
    "    return pathdict\n",
    "        \n",
    "def generateSimplePaths_crawljax(resultfile,baseurl):\n",
    "    DG,data = makeGraph_crawljax(resultfile,baseurl)\n",
    "    pathdict = {}\n",
    "    for node in tqdm(DG.nodes):\n",
    "        paths = nx.all_simple_paths(DG, source=\"index\", target=node)\n",
    "        pathlist = []\n",
    "        for path in paths:\n",
    "            i=0\n",
    "            temp = []\n",
    "            while(i<len(path)-1):    \n",
    "                for edge in data[\"edges\"]:\n",
    "                    if edge[\"from\"]==path[i] and edge[\"to\"]==path[i+1]:\n",
    "                        temp.append(edge[\"id\"])\n",
    "                i+=1\n",
    "            pathlist.append(temp)\n",
    "        if len(pathlist)>100:\n",
    "            if node in pathdict:\n",
    "                pathdict[node].extend(pathlist[0:100])\n",
    "            else:\n",
    "                pathdict[node] = pathlist[0:100]\n",
    "        else:\n",
    "            if node in pathdict:\n",
    "                pathdict[node].extend(pathlist)\n",
    "            else:\n",
    "                pathdict[node] = pathlist\n",
    "        #pathdict[node] = pathlist\n",
    "    return pathdict\n",
    "\n",
    "from itertools import product\n",
    "def splitstring(S):\n",
    "    s = S.split(\"->\")\n",
    "    i=1\n",
    "    result = s[0].split(\"|\")\n",
    "    while(i<len(s)-1):\n",
    "        result= [x[0]+\"->\"+x[1] for x in product(result,s[i].split(\"|\"))]\n",
    "        i+=1\n",
    "    #temp = [x.split(\"->\") for x in result]\n",
    "    return [x.split(\"->\") for x in result]\n",
    "\n",
    "def generateLocalSimplePaths_QExplore(statedict):\n",
    "    DG,stateNamesBig,stateNamesSmall,indexlist,SFG,edgemap = makeGraph_Qexplore(statedict)\n",
    "    pathdict = {}\n",
    "    for node in tqdm(DG.nodes):\n",
    "        for index in indexlist:\n",
    "            if node!=stateNamesBig[index]:\n",
    "                paths = nx.all_simple_paths(DG, source=stateNamesBig[index], target=node)\n",
    "                pathlist = []\n",
    "                for path in paths:\n",
    "                    i=0\n",
    "                    #temp = []\n",
    "                    s = \"\"\n",
    "                    while(i<len(path)-1):\n",
    "                        edar = []\n",
    "                        for edge in SFG[stateNamesSmall[path[i]]][\"edges\"]:\n",
    "                            if edge[\"state\"]==stateNamesSmall[path[i+1]]:\n",
    "                                #temp.append(path[i]+edge[\"action\"])\n",
    "                                #print(\"hello\")\n",
    "                                edar.append(path[i]+str(edgemap[edge[\"action\"]]))\n",
    "                        s+=\"|\".join(set(edar))\n",
    "                        s+=\"->\"\n",
    "                        i+=1\n",
    "                    temp = splitstring(s)\n",
    "                    pathlist.extend(temp)\n",
    "                if len(pathlist)>100:\n",
    "                    if node in pathdict:\n",
    "                        pathdict[node].extend(pathlist[0:100])\n",
    "                    else:\n",
    "                        pathdict[node] = pathlist[0:100]\n",
    "                else:\n",
    "                    if node in pathdict:\n",
    "                        pathdict[node].extend(pathlist)\n",
    "                    else:\n",
    "                        pathdict[node] = pathlist\n",
    "                #try:\n",
    "                #    print(stateNamesBig[index],node,pathdict[\"index2\"])\n",
    "                #except:\n",
    "                #    pass\n",
    "                \n",
    "    return pathdict\n",
    "\n",
    "\n",
    "def getpathSimilarity(path1,path2):\n",
    "    A = set(path1)\n",
    "    B = set(path2)\n",
    "    shared = len(A.intersection(B))\n",
    "    pathsim = (2*shared)/(len(A)+len(B))\n",
    "    return pathsim\n",
    "\n",
    "def calculate_Average_NavigationalDiversity(data):\n",
    "    keys = [key for key in data.keys() if data[key]!=[]]\n",
    "    diversity = []\n",
    "    for key in tqdm(keys):\n",
    "        paths = data[key]\n",
    "        sim = []\n",
    "        for path1,path2 in product(paths,paths):\n",
    "            sim.append(getpathSimilarity(path1,path2))\n",
    "        sim = np.array(sim)\n",
    "        if np.sum(sim==1)==sim.shape[0]:\n",
    "            diversity.append(1)\n",
    "        else:\n",
    "            diversity.append(1-np.min(sim))\n",
    "    return np.mean(diversity)\n",
    "\n",
    "def calculate_TestSuitSize(data):\n",
    "    keys = [key for key in data.keys() if data[key]!=[]]\n",
    "    Total = 0\n",
    "    for key in tqdm(keys):\n",
    "        paths = data[key]\n",
    "        sim = []\n",
    "        for path1,path2 in product(paths,paths):\n",
    "            sim.append(getpathSimilarity(path1,path2))\n",
    "        sim = np.array(sim)\n",
    "        Total+=np.sum(sim==0)+1\n",
    "    return Total\n",
    "\n",
    "def calculateTestModelSize(data):\n",
    "    edge = []\n",
    "    for k in data.keys():\n",
    "        for path in data[k]:\n",
    "            edge.extend(path)\n",
    "    return edge\n",
    "\n",
    "def generateSimpleStatePaths_QExplore(statedict):\n",
    "    DG,stateNamesBig,stateNamesSmall,indexlist,SFG,edgemap = makeGraph_Qexplore(statedict)\n",
    "    pathdict = {}\n",
    "    for node in tqdm(DG.nodes):\n",
    "        pathlist = []\n",
    "        for index in indexlist:\n",
    "            paths = nx.all_simple_paths(DG, source=stateNamesBig[index], target=node)\n",
    "            pathlist.extend([path for path in paths])\n",
    "        if len(pathlist)>100:\n",
    "            pathlist = pathlist[0:100]\n",
    "        pathdict[node] = pathlist\n",
    "    return pathdict\n",
    "        \n",
    "def generateSimpleStatePaths_crawljax(resultfile,baseurl):\n",
    "    DG,data = makeGraph_crawljax(resultfile,baseurl)\n",
    "    pathdict = {}\n",
    "    for node in tqdm(DG.nodes):\n",
    "        paths = nx.all_simple_paths(DG, source=\"index\", target=node)\n",
    "        AA = [path for path in paths]\n",
    "        if len(AA)>100:\n",
    "            pathdict[node] = AA[0:100]\n",
    "        else:\n",
    "            pathdict[node] = AA\n",
    "    return pathdict\n",
    "\n",
    "def calculateDomDiveristy(x,y,path):\n",
    "    tree1,n1 = generateTree(x)\n",
    "    tree2,n2 = generateTree(y)\n",
    "    t1 = Tree.from_text(tree1)\n",
    "    t2 = Tree.from_text(tree2)\n",
    "    apted = APTED(t1, t2)\n",
    "    ted = apted.compute_edit_distance()\n",
    "    DD = ted/max(n1,n2)\n",
    "    with open(path,\"w\") as file:\n",
    "        file.write(str(DD))\n",
    "        \n",
    "def makeUniqueDom(backup,path):\n",
    "    from shutil import copyfile,rmtree\n",
    "    import time\n",
    "    if os.path.exists(backup):\n",
    "        #shutil.rmtree(backup)\n",
    "        #os.mkdir(backup)\n",
    "        pass\n",
    "    else:\n",
    "        os.mkdir(backup)\n",
    "\n",
    "    doms = os.listdir(path)\n",
    "    for dom in doms:\n",
    "        copyfile(os.path.join(path,dom), os.path.join(backup,dom))\n",
    "    \n",
    "    for dom1 in tqdm(doms):\n",
    "        domlist = []\n",
    "        if dom1 in os.listdir(path) and dom1.split(\".\")[-1]==\"html\":\n",
    "            tree1,n1 = generateTree(os.path.join(path,dom1))\n",
    "            t1 = Tree.from_text(tree1)\n",
    "            for dom2 in os.listdir(path):\n",
    "                if dom2.split(\".\")[-1]==\"html\":\n",
    "                    if dom1!=dom2:\n",
    "                        tree2,n2 = generateTree(os.path.join(path,dom2))\n",
    "                        t2 = Tree.from_text(tree2)\n",
    "                        apted = APTED(t1, t2)\n",
    "                        ted = apted.compute_edit_distance()\n",
    "                        if ted<1:\n",
    "                            domlist.append(dom2)\n",
    "            for d in domlist:\n",
    "                os.remove(os.path.join(path,d))\n",
    "        time.sleep(0.5)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# make Unique STATES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "source": [
    "makeUniqueDom(\"./dombackup\",\"./doms\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "source": [
    "makeUniqueDom(\"./Qbackup\",\"./Q_Result\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DOM DIVERSITY\n",
    "Run process.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Navigational Functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "source": [
    "Qpaths = generateLocalSimplePaths_QExplore(\"./Q.map\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "source": [
    "import json\n",
    "with open(\"qpaths.json\", \"w\") as outfile:  \n",
    "    json.dump(Qpaths, outfile)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "source": [
    "#import json\n",
    "#with open(\"paths.json\") as json_file:\n",
    "#    Qpaths = json.load(json_file)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "source": [
    "cpaths = generateSimplePaths_crawljax(\"./result.json\",\"http://192.168.1.68/timeclock\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "source": [
    "import json\n",
    "with open(\"cpaths.json\", \"w\") as outfile:  \n",
    "    json.dump(cpaths, outfile)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "source": [
    "#Qdiversity = calculate_Average_NavigationalDiversity(Qpaths)\n",
    "#Qdiversity"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# run processpathfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test model size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "source": [
    "#Qpaths = generateLocalSimplePaths_QExplore(\"./Q.map\")\n",
    "len(set(calculateTestModelSize(Qpaths)))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "source": [
    "len(set(calculateTestModelSize(cpaths)))"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Suit Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "source": [
    "A = generateSimpleStatePaths_QExplore(\"./Q.map\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "source": [
    "B = generateSimpleStatePaths_crawljax(\"./result.json\",\"http://192.168.1.68/timeclock\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "source": [
    "calculate_TestSuitSize(A)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "source": [
    "calculate_TestSuitSize(B)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Model Size Unique\n",
    "run process.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HTML Coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "source": [
    "import os\n",
    "import cryptohash as chash\n",
    "def traverseTree(tree,unique=set()):\n",
    "    unique.add(tree.name)\n",
    "    for x in tree.children:\n",
    "        traverseTree(x,unique)\n",
    "    return unique"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "source": [
    "path = \"./Q_Result/\"\n",
    "exclude = [path+\"index.html\",path+\"temp.html\"]\n",
    "states = [file for file in glob.glob(path+\"*.html\") if file not in exclude]\n",
    "totaldomq = set()\n",
    "for state in tqdm(states):\n",
    "    tree,nodes = generateTree(state)\n",
    "    tree = Tree.from_text(tree)\n",
    "    taglist = traverseTree(tree)\n",
    "    soup = makeTree(state)\n",
    "    for tags in taglist:\n",
    "        for tag in soup.find_all(tags):\n",
    "            totaldomq.add(tag)\n",
    "len(totaldomq)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "source": [
    "path = \"./doms/\"\n",
    "exclude = [path+\"temp.html\"]\n",
    "states = [file for file in glob.glob(path+\"*.html\") if file not in exclude]\n",
    "totaldomc = set()\n",
    "for state in tqdm(states):\n",
    "    tree,nodes = generateTree(state)\n",
    "    tree = Tree.from_text(tree)\n",
    "    taglist = traverseTree(tree)\n",
    "    soup = makeTree(state)\n",
    "    for tags in taglist:\n",
    "        for tag in soup.find_all(tags):\n",
    "            totaldomc.add(tag)\n",
    "len(totaldomc)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "source": [
    "count = 0\n",
    "with open(\"qpaths.json\") as json_file:\n",
    "    data = json.load(json_file)\n",
    "\n",
    "for k in data.keys():\n",
    "    count+=len(data[k])\n",
    "count"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "source": [
    "count = 0\n",
    "with open(\"cpaths.json\") as json_file:\n",
    "    data = json.load(json_file)\n",
    "\n",
    "for k in data.keys():\n",
    "    count+=len(data[k])\n",
    "count"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
